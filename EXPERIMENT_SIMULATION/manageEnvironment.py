'''
This script permits with the other in the folder ones to simulate an Erwan Renaudo's 
experiment : 
"Renaudo, E. (2016). Des comportements flexibles aux comportements habituels: 
Meta-apprentissage neuro-inspiré pour la robotique autonome (Doctoral dissertation, 
Université Pierre et Marie Curie (Paris 6))". 
In this experiment, a turtlebot navigates in an arena discretized in states. It can
move in 8 directions (actions). Its goal is to find the rewarded state. The 
environement of the agent is based on a model of transition generated by the real 
robot. This script simulated the effect of the action's agent on the environment
( = the displacement of the agent across the states)
'''

from ClassMapB import *
from ParseMap import *

def initialize_environement_from_file(name_file,key_states_file,action_space):
	"""
	# Initialize the environment from a json-compatible file
	"""
	# -------------------------------------------------------------------------------
	# Load the list of initial states and the rewarded state
	init = list()
	listState = list()
	listReward = list()
	listDepartState = list()
	
	with open(key_states_file,'r') as file1:
		for line in file1:
			if line.split(" ")[0] == "init":
				listDepartState = listDepartState + list(map(int, line.split(" ")[1:]))
				
			elif line.split(" ")[0] == "goal":
				goal = int(line.split(" ")[1])
				win_reward = int(line.split(" ")[2])

	
	reward={"state":goal,"value":win_reward}
	listState=Buildlist_state(name_file,action_space)
	size=len(listState)
	environement=Environement(listState,reward,listDepartState,size,action_space)
	# -------------------------------------------------------------------------------
	return environement
	# -------------------------------------------------------------------------------

	
def get_id_around(n,id,size): # function that finds the id of the next state to be reached by chosing the action n
	i=id%size
	j=id//size
	i_around = -1
	j_around = -1
	if n==0:
		i_around=i
		j_around=j-1
	elif n==1:
		i_around=i+1
		j_around=j
	elif n==2:
		i_around=i-1
		j_around=j+1
		
	elif n==3:
		i_around=i-1
		j_around=j
	elif n==4:
		i_around=i-1
		j_around=j-1
	elif n==5:
		i_around=i+1
		j_around=j-1
	elif n==6:
		i_around=i+1
		j_around=j+1
	elif n==7:
		i_around=i-1
		j_around=j+1

	if i_around <0 or i_around >size-1 or j_around>size-1 or j_around<0: # if the action leads to a movement outside of the map borders, the agent doen't change its position
			id_around=id
	else :
		id_around=j_around*size+i_around
	
	
	return id_around

	
def idToCoord(id,size):# function that returns the matrix coordinates i and j depending on the State id
	i=id%size
	j=id//size
	return i, j

def CoordToId(i,j,size):# function that returns the State id depending on the ,matrix coordinates i and j (i = X-axis, j = Y-axis)
	return j*size + i

def initialize_environement_determinist(size,numberA,goal,win_reward,listDepartState):# create size*size square map with determinist outcome numberA =4 or 8 map 
	''' id representation 
		1 2 3 
		4 5 6 
		7 8 9 
	'''
	
	listState = [list()] * (size*size)

	for i in range(size*size):
		listT=[list()] * numberA#listTransition
		id=i
		for action in range(numberA):
			listT[action]=[{"state":get_id_around(action,id,size), "prob":1}]
		listState[id]=State(id,listT)
			
	reward={"state":goal,"value":win_reward}
	environement=Environement(listState,reward,listDepartState,size,numberA)
	return environement


def update_robot_position(environement, start, action):
	
	"""
	Simulate the effect of the robot's decision on the environement, that is to say,
	the identify of new state reaches after do the action in the previous state and 
	the reward obtains in this new state

	Here, start is not the start of an experiment, but the current position of the bot.
	"""
	start = int(start) #amelioration possible ne plus passer par des str en entrée
	# -------------------------------------------------------------------------------
	if environement.reward["state"]==start:
		
		arrival = environement.chooseDepart()
	else:
		arrival = environement.listState[start].chooseState(action)
			
	if environement.reward["state"]==arrival:
		reward= environement.reward["value"]
	else:
		reward= 0
	# ---------------------------------------------------------------------------
	return reward, str(arrival)
	# -------------------------------------------------------------------------------




