# ------- Experiment simulation files -------

## parameters.txt : 
contains values for the MB, MF agents and the Meta Controller.  The parameters are in the following order:

**MF** *alpha, gamma, beta, replay budget, delta threshold for replay buffer*

**MB** *gamma, beta, random inference budget, prioritized inference budget, delta threshold for priority queue, forward trajectory budget*

**MC** *beta*

## keyStates.txt :
contains informations about key states (e.g rewarding states)

## realisticWorld :
model generated by the real turtlebot, with map from paper https://arxiv.org/abs/2004.14698 


## agentModelBased.py

The model based agent. Its exact learning algorithm is defined by its *module*. The right module is created with the module tag  (attribute *module_type* in the agent).

## agentModelFree.py

The model free agent. Its exact learning algorithm is defined by its *module*. The right module is created with the module tag  (attribute *module_type* in the agent).

## turtlebotSimulator.py :
Main file to launch an experiment. In the console, the format to launch an experiment is the following:

**"python3   turtlebotSimulator.py *[log_file_id]* ./realisticWorld ./keyStates.txt ./parameters.txt -c *[meta_controller_mode]* -d *[number_of_time_steps]* -w *[probability_time_window]* -n -l -f *[MF_module_tag]* -b *[MB_module_tag]*"**

This is an example of what the command can look like:

*"python3  -W ignore turtlebotSimulator.py 1 ./realisticWorld ./keyStates.txt ./parameters.txt -c "Entropy_and_time" -d 4000 -w 30 -n -l -f 'dqn-prio' -b 'value-iteration-shuffle-budget"*

python  -W ignore test_uni.py 20 ./environement.txt ./keyStates.txt ./parameters.txt -c "Entropy_and_time" -d 10000 -w 30  -f 'q-learning' -b 'value-iteration-shuffle-budget'

**Note:** Adding -W ignore after python3 is not mandatory but can help have more visibility in the console by removing future warning.


## manageEnvironment.py :
Environment management & response

## metaController.py : 
Meta controller selecting agents according the the following modes:

**'random'**

**"MF_only"**

**"MB_only"**

**"Entropy_and_time"**

**"Entropy_only"**


## utility.py : 
helper functions

# ---> Tutorial to add a new module

If you want to add a new module to the project:

### 1) Make sure the new module class comports the following functions (with a similar role to the ones already implemented):
--> an initialization method (the arguments depend of the module)

--> get_actions_prob(state)

--> get_plan_time(state)

--> run(action_count, cumulated_reward, reward_obtained, previous_state, final_decision, current_state, who_plan_local[current_state]["MB"]) if this is a MB module

--> run(action_count, cumulated_reward, reward_obtained, previous_state, final_decision, current_state, who_plan_local[current_state]["MF"]) if this is a MF module

### 2) Add the module in the corresponding agent (MB or MF)

To begin with, the module class has to be imported in the corresponding agent, at the beginning. Then, in the **init** function, a test to check the module tag has to be conducted, and the module can be initialized with its arguments if the test is sucessful. Only one of the files **agentModelFree.py** or **agentModelBased.py** is modified during this process.

### 3) Only if needed: add more parameters 

In case the new module has more parameters than what the previous modules were already using, new parameters can be added in the **parse_parameters** function of **turtlebotSimulator.py**

### 4) Not mandatory : change the titles of the log files

In the initialization of **metaController.py**, it is possible to change the log files titles according to the module used, but it is not mandatory, and the logs will still be correctly outputed without that step. 

exemple of what a file wall look like with state1 id of a state and direction 0 if we want to put a complete wall and 1 for a unilateral wall. iter is when we want to put the wall (action_count)
[{"iter":201, "list_wall":[ [{"state1":6, "state2":7, "direction": 0},{"state1":1, "state2":35, "direction": 0}], [{"state1":20, "state2":21, "direction": 0}] ]},
 {"iter":203, "list_wall":[ [{"state1":6, "state2":9, "direction": 0},{"state1":1, "state2":25, "direction": 1}] ]}
]


[{"iter":1601, "new_goal": {"state":12,"value":1}},
 {"iter":1605, "new_goal": {"state":13,"value":1}},
 {"iter":1609, "new_goal": {"state":18,"value":1}},
 {"iter":1607, "new_goal": {"state":19,"value":1}},
 {"iter":1609, "new_goal": {"state":16,"value":1}}]